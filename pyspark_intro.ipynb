{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to PySpark\n",
    "\n",
    "Some exploration into using PySpark for Data Science. \n",
    "\n",
    "Generally, pandas should only be used with 5 to 10 times as much RAM as the size of your dataset, whereas PySpark is scalable and allows for parallel programming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|hello|\n",
      "+-----+\n",
      "|spark|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.sql(\"select 'spark' as hello\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data\n",
    "\n",
    "Using NYC flights in 2013:\n",
    "- Converting to parquet format and reloading so that only data used is loaded to memory\n",
    "- Query spark dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[year: int, month: int, day: int, dep_time: string, sched_dep_time: int, dep_delay: string, arr_time: string, sched_arr_time: int, arr_delay: string, carrier: string, flight: int, tailnum: string, origin: string, dest: string, air_time: string, distance: int, hour: int, minute: int, time_hour: string]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_location = \"data/flight_data.csv\"\n",
    "df = spark.read.format(\"csv\").option(\"inferSchema\", True).option(\"header\", True).load(file_location)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[year: int, month: int, day: int, dep_time: string, sched_dep_time: int, dep_delay: string, arr_time: string, sched_arr_time: int, arr_delay: string, carrier: string, flight: int, tailnum: string, origin: string, dest: string, air_time: string, distance: int, hour: int, minute: int, time_hour: string]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# df.write.save(\"data/flight_data_parquet\", format='parquet')\n",
    "df = spark.read.load(\"data/flight_data_parquet\")\n",
    "display(df)\n",
    "# df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert air time column type\n",
    "from pyspark.sql.types import *\n",
    "df = df.withColumn(\"air_time\", df[\"air_time\"].cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+--------------+\n",
      "|year|month|total_distance|\n",
      "+----+-----+--------------+\n",
      "|2013|    1|      27188805|\n",
      "|2013|    2|      24975509|\n",
      "|2013|    3|      29179636|\n",
      "|2013|    4|      29427294|\n",
      "|2013|    5|      29974128|\n",
      "|2013|    6|      29856388|\n",
      "|2013|    7|      31149199|\n",
      "|2013|    8|      31149334|\n",
      "|2013|    9|      28711426|\n",
      "|2013|   10|      30012086|\n",
      "|2013|   11|      28639718|\n",
      "|2013|   12|      29954084|\n",
      "+----+-----+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"flights\")\n",
    "year_flights = spark.sql(\"\"\"\n",
    "    select year, month, sum(distance) as total_distance\n",
    "    from flights\n",
    "    group by 1, 2\n",
    "    order by 1, 2\n",
    "    \"\"\")\n",
    "year_flights.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting\n",
    "\n",
    "Either convert to a pandas dataframe or use Apache Zeppelin to plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_flights_pd = year_flights.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1bb15e55248>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x=\"month\", y=\"total_distance\", data=year_flights_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Fitting\n",
    "\n",
    "While scikit-learn is great when working with pandas, it doesnâ€™t scale to large data sets in a distributed environment. MLlib is most generally used and operates natively on spark dataframes (although it is possible to parallelize scikit-learn with spark). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler  # Create a vector representation for features\n",
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop nulls\n",
    "df = df.filter(df['air_time'].isNotNull())\n",
    "df = df.filter(df['distance'].isNotNull())\n",
    "# df.drop.na()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple model for air time vs flight distance\n",
    "assembler = VectorAssembler(inputCols=['air_time'], outputCol='features')\n",
    "train_df = assembler.transform(df)\n",
    "lr_model = LinearRegression(featuresCol = 'features', labelCol='distance').fit(train_df)\n",
    "trainingSummary = lr_model.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [7.781414355687039]\n",
      "RMSE: 100.400201\n",
      "R2: 0.981387\n"
     ]
    }
   ],
   "source": [
    "print(\"Coefficients: \" + str(lr_model.coefficients))\n",
    "print(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\n",
    "print(\"R2: %f\" % trainingSummary.r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A high R2 score means that the distance travelled is well explained by the flight air time, as would be expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling Pandas Operations\n",
    "\n",
    "We can use pandas UDFs (user defined functions) to perform distributed computing with pandas dataframes within a spark environment. This is the preferred method of parallelization because it distributes threads across driver nodes. Note that we use the `groupby` and `apply` functions on a spark dataframe.\n",
    "\n",
    "This avoids the need to convert the whole dataframe using toPandas(), which will fail for large dataframes due to an out of memory exception. We can thus scale to large datasets as long as we have a good way to partition the dataframe. \n",
    "\n",
    "This requires pyarrow. `pip install pyarrow`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import pandas_udf, PandasUDFType\n",
    "from pyspark.sql.functions import col, count, rand, collect_list, explode, struct, lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "350217607"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregate function is to sum\n",
    "year_flights_pd.dropna(inplace=True)\n",
    "total_distance = sum(year_flights_pd['total_distance'])\n",
    "total_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------------+\n",
      "|year|total_distance|\n",
      "+----+--------------+\n",
      "|2013|     350217607|\n",
      "+----+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "group_column = 'year'\n",
    "x_columns = ['total_distance']\n",
    "schema = year_flights.select(group_column, *x_columns).schema  # define the output format\n",
    "\n",
    "@pandas_udf(schema, PandasUDFType.GROUPED_MAP)\n",
    "# Input/output are both a pandas.DataFrame\n",
    "def year_sum(pdf):\n",
    "    group_key = pdf[group_column].iloc[0]\n",
    "    x = pdf[x_columns]\n",
    "    total_distance = x.sum()\n",
    "    return pd.DataFrame({group_column: [group_key],\n",
    "                         x_columns[0]: [total_distance]})\n",
    "\n",
    "year_flights.groupby(group_column).apply(year_sum).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|count(total_distance)|\n",
      "+---------------------+\n",
      "|                   12|\n",
      "+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "@pandas_udf(year_flights.schema, PandasUDFType.GROUPED_MAP)\n",
    "# Input/output are both a pandas.DataFrame\n",
    "def pandas_subtract_mean(pdf):\n",
    "    return pdf.assign(total_distance=pdf.total_distance - pdf.total_distance.mean())\n",
    "\n",
    "year_flights.groupby('year').apply(pandas_subtract_mean).agg(count(col('total_distance'))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------+-------------------+\n",
      "|year|                 x1|                 x2|\n",
      "+----+-------------------+-------------------+\n",
      "|2013|0.07333048090834393|0.06719204507058933|\n",
      "+----+-------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# df2 has four columns: id, y, x1, x2\n",
    "df2 = year_flights.withColumn('y', rand()).withColumn('x1', rand()).withColumn('x2', rand()).select('year', 'y', 'x1', 'x2')\n",
    "\n",
    "group_column = 'year'\n",
    "y_column = 'y'\n",
    "x_columns = ['x1', 'x2']\n",
    "schema = df2.select(group_column, *x_columns).schema\n",
    "\n",
    "@pandas_udf(schema, PandasUDFType.GROUPED_MAP)\n",
    "# Input/output are both a pandas.DataFrame\n",
    "def ols(pdf):\n",
    "    group_key = pdf[group_column].iloc[0]\n",
    "    y = pdf[y_column]\n",
    "    X = pdf[x_columns]\n",
    "    X = sm.add_constant(X)\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    return pd.DataFrame([[group_key] + [model.params[i] for i in x_columns]], columns=[group_column] + x_columns)\n",
    "\n",
    "beta = df2.groupby(group_column).apply(ols)\n",
    "beta.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallelization \n",
    "\n",
    "There are other ways to parallelize operations outside of pandas UDFs:\n",
    "- If we use spark dataframes and libraries then the task will be natively parallelized and distributed\n",
    "- The multiprocessing library provides a thread abstraction to create concurrent threads of execution, this doesn't however distribute across driver nodes unless using spark dataframes or libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing.pool import ThreadPool\n",
    "pool = ThreadPool(2)  # 2 concurrent threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 7, 8]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = [1, 2, 3]\n",
    "base_val = 5\n",
    "def add_val(a, b):\n",
    "    return a + b\n",
    "\n",
    "pool.map(lambda x: add_val(base_val, x), parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b  c\n",
       "0  1  2  5"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_df = pd.DataFrame({'a': [1, 2, 3, 4],\n",
    "                        'b': [2, 2, 3, 3],\n",
    "                        'c': [5, 4, 3, 2]\n",
    "                       })\n",
    "\n",
    "def return_val(df, key):\n",
    "    return df[df['a'] == key]\n",
    "\n",
    "return_df = pool.map(lambda x: return_val(base_df, x), parameters)  # list of pandas dataframes\n",
    "return_df[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
